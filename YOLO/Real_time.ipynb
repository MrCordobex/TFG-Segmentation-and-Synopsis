{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_yolo(model_path, mode, confidence_threshold= 0.5, device=0):\n",
    "    \"\"\"\n",
    "    Runs a YOLOv8 detection or segmentation loop on the webcam.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to the .pt model (e.g. 'yolov8n-seg.pt' or 'yolov8n.pt').\n",
    "        mode (str): 'detect' for bounding boxes, 'segment' for segmentation masks + boxes.\n",
    "        confidence_threshold: Confidence threshold between 0.0 and 1.0.\n",
    "        device: Camera device index (default 0).\n",
    "    \"\"\"\n",
    "    # Load the YOLO model\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # Open the webcam\n",
    "    cap = cv2.VideoCapture(device)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Could not open camera index {device}\")\n",
    "\n",
    "    # Prepare random colors for segmentation\n",
    "    if mode == \"segment\":\n",
    "        num_classes = len(model.names)\n",
    "        colors = np.random.randint(0, 255, size=(num_classes, 3), dtype=np.uint8)\n",
    "\n",
    "    window_name = f\"YOLO - {mode.capitalize()} (for exit press 'Q')\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Perform inference\n",
    "            results = model(frame)\n",
    "            result = results[0]\n",
    "\n",
    "            if mode == \"detect\":\n",
    "                display_frame = frame.copy()\n",
    "                # Draw bounding boxes\n",
    "                for box in result.boxes:\n",
    "                    conf = float(box.conf)\n",
    "                    if conf < confidence_threshold:\n",
    "                        continue\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "                    cls = int(box.cls.cpu().numpy()[0])\n",
    "                    label = f\"{model.names[cls]}: {conf:.2f}\"\n",
    "                    cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(display_frame, label, (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            elif mode == \"segment\":\n",
    "                # Check if masks are available\n",
    "                if result.masks is None:\n",
    "                    raise RuntimeError(\n",
    "                        f\"Model '{model_path}' does not support segmentation. \"\n",
    "                        \"Please use a segmentation model like 'yolov8n-seg.pt'.\"\n",
    "                    )\n",
    "                display_frame = frame.copy()\n",
    "\n",
    "                # Extract data\n",
    "                boxes = result.boxes.xyxy.cpu().numpy()\n",
    "                scores = result.boxes.conf.cpu().numpy()\n",
    "                classes = result.boxes.cls.cpu().numpy().astype(int)\n",
    "                masks = result.masks.data.cpu().numpy()\n",
    "\n",
    "                # Overlay masks and draw boxes\n",
    "                overlay = frame.copy()\n",
    "                for i, conf in enumerate(scores):\n",
    "                    if conf < confidence_threshold:\n",
    "                        continue\n",
    "                    x1, y1, x2, y2 = map(int, boxes[i])\n",
    "                    cls = classes[i]\n",
    "                    mask = masks[i] > 0.5\n",
    "\n",
    "                    color = [int(c) for c in colors[cls]]\n",
    "                    mask_color = np.zeros_like(frame, dtype=np.uint8)\n",
    "                    mask_color[mask] = color\n",
    "\n",
    "                    # Blend mask onto the frame\n",
    "                    overlay = cv2.addWeighted(overlay, 1.0, mask_color, 0.5, 0)\n",
    "                    cv2.rectangle(overlay, (x1, y1), (x2, y2), color, 2)\n",
    "                    label = f\"{model.names[cls]}: {conf:.2f}\"\n",
    "                    cv2.putText(overlay, label, (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "                display_frame = overlay\n",
    "            else:\n",
    "                raise ValueError(\"mode must be 'detect' or 'segment'\")\n",
    "\n",
    "            # Show the frame\n",
    "            cv2.imshow(window_name, display_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "#modes=[\"detect\", \"segment\"]\n",
    "#device=0 (webcam)\n",
    "\n",
    "run_yolo(\"yolov8n-seg.pt\", \"segment\", confidence_threshold=0.5,device=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
